#import "@preview/touying:0.5.3": *
#import "@preview/fontawesome:0.3.0": *
#import "quarto_theme.typ": *

#show: clean-theme.with(
  aspect-ratio: "16-9",
  font-size: 16pt
)

#title-slide(
  title: [R√©solution des mod√®les DSGE],
  subtitle: [ECO432 - Macro√©conomie],
  authors: (
    (name: [Pablo Winant], affiliation: [], email: [], orcid: []),
  ),
  date: [2026/02/12],
)

==

#align(center)[
#image("assets/warning.png")
]

= Introduction
<introduction>
== 
<section>


Quelle est la principale sp√©cificit√© de la mod√©lisation √©conomique ?

#pause

En (macro)√©conomie, on #emph[mod√©lise] le comportement des agents √©conomiques en sp√©cifiant :

- leur objectif $ max_(c_t) E_t sum_(s >= t) beta^s U (c_s) $ $ max pi_t $ $ dots $
- leurs contraintes (contrainte budg√©taire, environnement √©conomique‚Ä¶)

#pause

Cela a des implications importantes :

- les mod√®les macro sont #emph[tourn√©s vers le futur]
  - ils reposent sur les anticipations
- les mod√®les macro doivent √™tre #strong[r√©solus]

Dans de nombreux cas, il n‚Äôexiste pas de forme ferm√©e pour la solution -\> il faut des #emph[techniques num√©riques]

== Dynare
<dynare>

#columns(2,[
  
- 1996 : Michel Juillard cr√©e un logiciel open source pour r√©soudre des mod√®les DSGE
  - DSGE : √©quilibre g√©n√©ral dynamique stochastique
  - g√©n√©ralement r√©solus autour d‚Äôun √©tat stationnaire
- Aujourd‚Äôhui environ 10 contributeurs.
  - $+$ des utilisateurs avanc√©s ayant contribu√© au code

- Il a √©t√© largement adopt√© :
  - premi√®re version sous Gauss
  - puis Matlab/Octave/Scilab
  - version la plus r√©cente en Julia
  - ‚Ä¶ et Python (voir #link("https://github.com/econforge/dyno.py")[dyno ü¶ñ] et ses notations simplifi√©es)

#colbreak()

#figure([
#box(image("assets/michel.jpeg"))
], caption: figure.caption(
position: bottom, 
[
Michel Juillard
]), 
kind: "quarto-float-fig", 
supplement: "Figure", 
)
])

== Les mod√®les DSGE dans les institutions
<dsge-models-in-institutions>
Aujourd‚Äôhui, la plupart des mod√®les DSGE construits dans les institutions ont une version Dynare (IMF/GIMF, EC/Quest, ECB/, NYFed/FRBNY)

- ils reposent g√©n√©ralement sur le #emph[mod√®le de taille interm√©diaire] de Smets & Wouters (10 √©quations)
- mais ils ont beaucoup grandi (\>\>100 √©quations)

#pause

Les institutions, port√©es par les chercheurs, diversifient leurs mod√®les

- Mod√®les semi-structurels
- Mod√®les d‚Äô√©quilibre g√©n√©ral calculable
- Mod√®les de r√©seau
- Mod√®les Agent-Based
- Mod√®les √† agents h√©t√©rog√®nes
- ...


= R√©soudre un mod√®le
<solving-a-model>
== Mod√®le DSGE
<model>
Voici une repr√©sentation tr√®s concise d‚Äôun mod√®le DSGE:

$ bb(E)_t [f (y_(t + 1) \, y_t \, y_(t - 1) \, epsilon_t)] = 0 $

#block[
#block[
#block[
Le #strong[probl√®me];:

- $y_t in bb(R)^n$: le vecteur des variables endog√®nes
- $epsilon_t in bb(R)^(n_e)$: le vecteur des variables exog√®nes
  - on suppose que $epsilon_t$ est un processus gaussien centr√©
- $f : bb(R)^n -> bb(R)^n$: les √©quations du mod√®le

]
]
#block[
#block[
La #strong[solution];:

- $g$ telle que $forall t \, y_t = g (y_(t - 1) \, epsilon_t)$

]
]
]

== Le timing des √©quations
<the-timing-of-the-equations>

#block[
#callout(
body: 
[
Dans un fichier Dynare, les √©quations du mod√®le sont cod√©es dans le bloc `model; ... ; end;`.

La variable $v_t$ (resp. $v_(t - 1)$, $v_(t + 1)$) est not√©e `v` ou `v(0)` (resp. `v(-1)`, `v(+1)`).

Dans dyno, c‚Äôest `v[t],v[t-1],v[t+1]`.


]
, 
title: 
[
Astuce
]
, 
background_color: 
rgb("#ccf1e3")
, 
icon_color: 
rgb("#00A047")
, 
icon: 
fa-lightbulb()

)
]
#strong[Convention g√©n√©rale de timing]

La nouvelle information arrive avec les innovations $epsilon_t$.

√Ä la date $t$, l‚Äôensemble d‚Äôinformation est engendr√© par $cal(F)_t = cal(F) (dots \, epsilon_(t - 3) \, epsilon_(t - 2) \, epsilon_(t - 1) \, epsilon_t)$

Par convention #emph[une variable endog√®ne porte l‚Äôindice $t$ si elle est connue pour la premi√®re fois √† la date $t$];.

#pause

On distingue plusieurs #strong[types de variables] selon leur apparition dans le mod√®le :

- variable de saut : appara√Æt en $t$ ou $t + 1$
- variable pr√©d√©termin√©e : appara√Æt en $t - 1$ et $t$ (√©ventuellement $t + 1$)
- variable statique : appara√Æt uniquement en $t$
  - peut s‚Äôexprimer comme fonction des autres variables


== √âtat stationnaire
<steady-state>
L‚Äô√©tat stationnaire d√©terministe v√©rifie :

$ f (overline(y) \, overline(y) \, overline(y) \, 0) = 0 $

Souvent, il existe une solution analytique.

Sinon, il faut recourir √† un solveur num√©rique pour r√©soudre

$ overline(y) -> f (overline(y) \, overline(y) \, overline(y) \, 0) $

#block[
#callout(
body: 
[
Dans Dynare, les valeurs d‚Äô√©tat stationnaire sont fournies dans le bloc `steadystate_model; ... ; end;`. On peut v√©rifier qu‚Äôelles sont correctes avec l‚Äôinstruction `check;`.

Pour trouver num√©riquement l‚Äô√©tat stationnaire : `steady;`.

]
, 
title: 
[
Astuce
]
, 
background_color: 
rgb("#ccf1e3")
, 
icon_color: 
rgb("#00A047")
, 
icon: 
fa-lightbulb()

)
]
== Le syst√®me implicite
<the-implicit-system>
En rempla√ßant la solution $ y_t = g (y_(t - 1) \, epsilon_t) $ dans le syst√®me $ bb(E)_t [f (y_(t + 1) \, y_t \, y_(t - 1) \, epsilon_t)] = 0 $

on obtient :

$ bb(E)_t [f (g (g (y_(t - 1) \, epsilon_t) \, epsilon_(t + 1)) \, g (y_(t - 1) \, epsilon_t) \, y_(t - 1) \, epsilon_t)] = 0 $

Il s‚Äôagit d‚Äôune √©quation qui d√©finit implicitement la fonction $g ()$

== L‚Äôespace d‚Äô√©tat
<the-state-space>
$ bb(E)_t [f (g (g (y_(t - 1) \, epsilon_t) \, epsilon_(t + 1)) \, g (y_(t - 1) \, epsilon_t) \, y_(t - 1) \, epsilon_t)] = 0 $

Dans cette expression, $y_(t - 1) \, epsilon_t$ est l‚Äôespace d‚Äô√©tat :

- il contient toute l‚Äôinformation disponible √† $t$ pour pr√©dire l‚Äô√©volution future de $(y_s)_(s >= t)$

#pause

En supprimant les indices temporels, l‚Äô√©quation doit √™tre v√©rifi√©e pour toute r√©alisation de $(y \, epsilon)$ $ forall (y \, epsilon) mid Phi (g) (y \, epsilon) = bb(E)_(epsilon') [f (g (g (y \, epsilon) \, epsilon ') \, g (y \, epsilon) \, y \, epsilon)] = 0 $

C‚Äôest une √©quation fonctionnelle $Phi (g) = 0$

== Chocs anticip√©s
<expected-shocks>
Approximation au premier ordre :

- Supposons $lr(|epsilon|) << 1$,$lr(|epsilon '|) << 1$

On effectue un d√©veloppement de Taylor par rapport au choc futur :

#pause

On utilise le fait que $bb(E) [epsilon^(')] = 0$.

Au premier ordre, les chocs anticip√©s ne jouent aucun r√¥le.

Pour capturer les comportements de pr√©caution (comme les primes de risque), il faut augmenter l‚Äôordre d‚Äôapproximation.

== Perturbation au premier ordre
<first-order-perturbation>
On obtient alors le syst√®me :

$ F (y \, epsilon) = f (g (g (y \, epsilon) \, 0) \, g (y \, epsilon) \, y \, epsilon) = 0 $

Une variante du #emph[th√©or√®me des fonctions implicites] permet alors d‚Äôobtenir une premi√®re approximation de $g$ :

$ g (y \, epsilon) = overline(y) + g_y^(') (y - overline(y)) + g_e^(') epsilon_t $

#pause

Les quantit√©s inconnues $g_y^(')$ et $g_e^(')$ sont obtenues par la #emph[m√©thode des coefficients ind√©termin√©s];. On substitue la premi√®re approximation dans le syst√®me puis on √©crit les conditions $ F_y^(') (overline(y) \, 0) = 0 $ $ F_epsilon^(') (overline(y) \, 0) = 0 $

== Calcul de $g_y^(')$
<computing-gprime_y>
Rappelons le syst√®me : $ F (y \, epsilon) = f (g (g (y \, epsilon) \, 0) \, g (y \, epsilon) \, y \, epsilon) = 0 $

On a $ F_y^(') (overline(y) \, 0) = f_(y_(t + 1))^(') g_y^(') g_y^(') + f_(y_t)^(') g_y^(') + f_(y_(t - 1))^(') = 0 $

#pause

$g_y^(')$ est la solution d‚Äôune √©quation de Riccati sp√©cifique $ A X^2 + B X + C $ o√π $A \, B \, C$ et $X = g_y^(')$ sont des matrices carr√©es $in bb(R)^n times bb(R)^n$

== Mod√®le d√©terministe du premier ordre
<first-order-deterministic-model>
Prenons une minute pour observer le mod√®le d√©terministe du premier ordre : $ A X^2 + B X + C $

D‚Äôapr√®s notre intuition en dimension 1, on sait qu‚Äôil doit y avoir plusieurs solutions

- comment les trouver ?
- comment s√©lectionner les bonnes ?

En l‚Äôabsence de chocs, la dynamique du mod√®le est donn√©e par $ y_t = X y_(t - 1) $

Quelle est la condition pour que le mod√®le soit stationnaire ?

#pause

\-\> la plus grande valeur propre de $X$ doit √™tre inf√©rieure √† 1


== Multiplicit√© des solutions
<multiplicity-of-solution>
On peut montrer que le syst√®me est associ√© √† $2 n$ valeurs propres g√©n√©ralis√©es :

$ lr(|lambda_1|) <= dots <= lr(|lambda_(2 n)|) $

Pour chaque choix $C$ de $n$ valeurs propres ($lr(|C|) = n$), on peut #emph[construire] une solution r√©cursive sp√©cifique $X_C$;. Elle a pour valeurs propres $C$.

#pause

Cela donne au moins $vec(2 n, n)$ combinaisons diff√©rentes.

#pause

Un mod√®le est bien d√©fini lorsqu‚Äôil existe #strong[exactement une solution non divergente];.

Cela est √©quivalent √† :

$ lr(|lambda_1|) <= dots <= lr(|lambda_n|) <= 1 < lr(|lambda_(n + 1)|) <= dots <= lr(|lambda_(2 n)|) $

== Exemple 1
<example-1>
Inflation anticip√©e :

$ pi_t = alpha pi_(t + 1) $ avec $alpha < 1$.

Est-il bien d√©fini ?

#pause

On peut r√©√©crire le syst√®me comme :

$ alpha pi_(t + 1) - pi_t + 0 pi_(t - 1) = 0 $

ou

$ pi_(t + 1) - (1 / alpha + 0) pi_t + (1 / alpha 0) pi_(t - 1) = 0 $

#pause

Les valeurs propres g√©n√©ralis√©es sont $0 <= 1 < 1 / alpha$.

#pause

La solution stable unique est $pi_t = 0 pi_(t - 1)$

== Exemple 2
<example-2>
√âquation d‚Äôaccumulation de dette d‚Äôun agent rationnel :

$ b_(t + 1) - (1 + 1 / beta) b_t + 1 / beta b_(t - 1) = 0 $

Est-il bien d√©fini ?

#pause

Deux valeurs propres g√©n√©ralis√©es $lambda_1 = 1 < lambda_2 = 1 / beta$

#pause

La solution unique non divergente est $b_t = b_(t - 1)$.

- il s‚Äôagit d‚Äôune #emph[racine unitaire]; : toute d√©viation initiale de $b_(t - 1)$ a des effets persistants

== Exemple 3
<example-3>
Processus de productivit√© : $ z_t = rho z_(t - 1) $ avec $rho < 1$ : bien d√©fini

#pause

Dans ce cas, il existe une valeur propre infinie cach√©e $oo$ associ√©e √† $z_(t + 1)$.

#pause

Pour comprendre, consid√©rons le syst√®me associ√© aux valeurs propres $m$ et $rho$ : $ z_(t + 1) - (m + rho) z_t + m rho z_(t - 1) = 0 $

$ 1 / m z_(t + 1) - (1 + rho / m) z_t + rho z_(t - 1) = 0 $

Ce qui correspond au mod√®le initial lorsque $m = oo$

#pause

Les valeurs propres g√©n√©ralis√©es sont $lambda_1 = rho <= 1 < lambda_2 = oo$

Plus g√©n√©ralement, toute variable qui n‚Äôappara√Æt pas en $t + 1$ cr√©e une valeur propre g√©n√©ralis√©e infinie.

== Un crit√®re de bonne d√©finition
<a-criterium-for-well-definedness>
En revenant √† la liste des valeurs propres, on met de c√¥t√© les valeurs infinies.

Le mod√®le est bien sp√©cifi√© ssi on peut ordonner les valeurs propres comme suit :

$ lr(|lambda_1|) <= dots <= lr(|lambda_n|) <= 1 < lr(|lambda_(n + 1)|) <= dots lr(|lambda_(n + k)|) <= underbrace(lr(|lambda_(n + k + 1)|) dots <= lr(|lambda_(2 n)|), upright("valeurs propres infinies")) $

#block[
#callout(
body: 
[
Le mod√®le satisfait le crit√®re de Blanchard-Kahn si le nombre de valeurs propres sup√©rieures √† un est exactement √©gal au nombre de variables #emph[apparaissant] en $t + 1$.

Dans ce cas, le mod√®le est bien d√©fini.

]
, 
title: 
[
Crit√®re de Blanchard-Kahn
]
, 
background_color: 
rgb("#dae6fb")
, 
icon_color: 
rgb("#0758E5")
, 
icon: 
fa-info()

)
]
== Calcul de la solution
<computing-the-solution>
Il existe plusieurs m√©thodes classiques pour calculer la solution de l‚Äô√©quation alg√©brique de Riccati : $ A X^2 + B X + C = 0 $

- d√©composition QZ
  - traditionnellement utilis√©e dans la litt√©rature DSGE depuis Chris Sims
  - un peu peu intuitive
- r√©duction cyclique
  - nouveau d√©faut dans Dynare, plus adapt√©e aux grands mod√®les
- it√©ration de Bernoulli (voir section "It√©ration lin√©aire dans le temps")
  - conceptuellement tr√®s simple

== Calcul de $g_e^(')$
<computing-gprime_e>
Maintenant que nous avons $g_y^(')$, comment obtenir $g_e^(')$ ?

Rappel : $ F (y \, epsilon) = f (g (g (y \, epsilon) \, 0) \, g (y \, epsilon) \, y \, epsilon) = 0 $

On a $ F_e^(') (overline(y) \, 0) = f_(y_(t + 1))^(') g_y^(') g_e^(') + f_(y_t)^(') g_e^(') + f_(epsilon_t)^(') = 0 $

√Ä pr√©sent, c‚Äôest simple :

$ g_e^(') = - (f_(y_(t + 1))^(') g_y^(') + f_(y_t)^('))^(- 1) f_(epsilon_t)^(') = 0 $

== La solution du mod√®le
<the-model-solution>
Le r√©sultat de la r√©solution du mod√®le : $ y_t = g_y y_(t - 1) + g_e epsilon_t $

C‚Äôest un AR(1), pilot√© par le choc exog√®ne $epsilon_t$.

#pause

Comme il s‚Äôagit d‚Äôune structure bien connue, on peut √©tudier le mod√®le avec

- des fonctions de r√©ponse impulsionnelle
- des simulations stochastiques

#pause

Ensuite, pour comparer le mod√®le aux donn√©es, on calcule

- moments implicites :
  - covariances, autocorr√©lations
- vraisemblance

L‚Äôoptimisation de l‚Äôajustement aux donn√©es s‚Äôappelle l‚Äô#emph[estimation] du mod√®le

= Conclusion
<sec-conclusion>
== Que peut-on faire avec la solution
<what-can-you-do-with-the-solution>
La solution d‚Äôun mod√®le trouv√©e par Dynare a une forme particuli√®rement simple : un AR(1)

- $y_t = X y_(t - 1) + Y epsilon_t$
- o√π les covariances $Sigma$ de $epsilon_t$ peuvent √™tre choisies par le mod√©lisateur

#pause

Avec cette solution, on peut

- calculer des moments (conditionnels et inconditionnels)
- effectuer des simulations stochastiques et des fonctions de r√©ponse impulsionnelle

#pause

== Aller plus loin
<going-further>
Confronter le mod√®le aux donn√©es avec Dynare

- ¬´ estimer ¬ª le mod√®le : calculer la vraisemblance d‚Äôune solution et la maximiser en choisissant les bons param√®tres
- ¬´ identifier ¬ª les chocs dans les donn√©es

Autres fonctionnalit√©s

- approximation d‚Äôordre sup√©rieur
- simulations en pr√©vision parfaite (non lin√©aires)
- plan de Ramsey
- politique discr√©tionnaire
- ‚Ä¶

= Annexe : It√©ration lin√©aire dans le temps
<sec:linear_time_iteration>
== It√©ration lin√©aire dans le temps
<linear-time-iteration>
Rappel du syst√®me √† r√©soudre : $ F (y \, epsilon) = f (g (g (y \, epsilon) \, 0) \, g (y \, epsilon) \, y \, epsilon) = 0 $

mais supposons maintenant que les r√®gles de d√©cision d‚Äôaujourd‚Äôhui et de demain sont diff√©rentes :

- aujourd‚Äôhui : $y_t = g (y_(t - 1) \, epsilon_t) = overline(y) + X y_(t - 1) + g_y epsilon_t$
- demain : $y_(t + 1) = tilde(g) (y_t \, epsilon_(t + 1)) = overline(y) + tilde(X) y_(t - 1) + tilde(g)_y epsilon_t$

Alors l‚Äô√©quation de Ricatti s‚Äô√©crit :

$ A tilde(X) X + B X + C = 0 $

== It√©ration lin√©aire dans le temps (2)
<linear-time-iteration-2>
L‚Äôalgorithme d‚Äôit√©ration lin√©aire dans le temps consiste √† r√©soudre la r√®gle de d√©cision $X$ aujourd‚Äôhui en fonction de la r√®gle de d√©cision de demain $tilde(X)$.

Cela correspond √† la formule simple :

$ X = - (A tilde(X) + B)^(- 1) C $

Et l‚Äôalgorithme complet peut √™tre d√©crit comme suit :

- choisir $X_0$
- pour tout $X_n$, calculer $X_(n + 1) = T (X_n) = - (A X_n + B)^(- 1) C$
  - r√©p√©ter jusqu‚Äô√† convergence

== It√©ration lin√©aire dans le temps (3)
<linear-time-iteration-3>
On peut montrer qu‚Äôen partant d‚Äôune condition initiale al√©atoire, l‚Äôalgorithme d‚Äôit√©ration lin√©aire dans le temps converge vers la solution $X$ de plus petit module :

$ underbrace(lr(|lambda_1|) <= dots <= lr(|lambda_n|), upright("Valeurs propres s√©lectionn√©es")) <= lr(|lambda_(n + 1)|) dots <= lr(|lambda_(2 n)|) $

Autrement dit, il trouve la bonne solution lorsque le mod√®le est bien sp√©cifi√©.

Comment v√©rifier qu‚Äôil est bien sp√©cifi√© ?

- $lambda_n$ est la plus grande valeur propre de la solution $X$
- qu‚Äôen est-il de $lambda_(n + 1)$ ?
  - $1 / lambda_(n + 1)$ est la plus grande valeur propre de $(A X + B)^(- 1) A$

== It√©ration lin√©aire dans le temps (4)
<linear-time-iteration-4>
D√©finissons $ M (lambda) = A lambda^2 + B lambda + C $

Pour toute solution $X$, $M (lambda)$ peut se factoriser ainsi : #footnote[Cas particulier du th√©or√®me de B√©zout. Facile √† v√©rifier dans ce cas]

$ M (lambda) = (lambda A + A X + B) (lambda I - X) $

et

$ det(M(lambda)) = underbrace(det(lambda A + A X + B), Q(lambda)) det(lambda I - X) $

Par construction, $Q(lambda)$ est un polyn√¥me dont les racines sont celles qui ne sont pas s√©lectionn√©es par la solution, c.-√†-d. $Lambda in "Sp"(X)$.

== It√©ration lin√©aire dans le temps (5)
<linear-time-iteration-5>
Pour $lambda != 0$, on a :

$ lambda in "Sp"((A X + B)^(-1) A) $

$ <=> det((A X + B)^(-1) A - I lambda) = 0 $

$ <=> det(1 / lambda A - I (A X + B)) = 0 $

$ <=> Q(1 / lambda) = 0 $

$ <=> 1 / lambda in Lambda in "Sp"(X) $

En clair, $(A X + B)^(- 1)$ contient toutes les valeurs propres qui ont √©t√© rejet√©es par la s√©lection de $X$.

En particulier, $rho((A X + B)^(-1) A) = 1 / min(Lambda in "Sp"(X))$.
